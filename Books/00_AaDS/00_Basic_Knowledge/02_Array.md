---
title: 数组
---

> 🚀 工欲善其事，必先利其器。

# 数组

在概述章节，粗略的过了一遍数据基本结构。

现在开始根据数据结构来分门别类学习。

在大部分语言中，数组都是从 0 开始编号的，但是你有没有想过，为什么数组要从 0 开始编号，而不是从 1 开始呢？从 1 开始不更符合我们的思维习惯吗？

## 数组是什么呢？

**数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。**

数组的定义中有几个关键字：

第一个**线性表**。线性表就是数据排成一条线一样的结构。每个线性表上的数据元素最多只有前和后两个方向。

第二个**连续的内存空间**。正是因为它就有连续的内存空间，它才有了一个非常强大的特性：“随机访问”。但是万物都是相对的，有利就有弊，这两个限制也让数组的很多操作变得非常艰难和低效，比如：删除数组中的数据，为了保证连续性，就需要把后面的数据元素搬移到前面来。

第三个**相同类型的数据**。数组中存储数据都是同一类型的，在许多语言中，数组只允许一种类型存在，当然也有像 JavaScript 这种弱类型语言，支持多种类型。

## 数组实现随机访问

既然知道了什么叫做数组，也知道了数组有一个非常强大的特性：“随机访问”。那么数组如何实现随机访问呢？

首先，我们拿一个长度为 10 到的 int 类型数组 `int[] a = new int[10]` 来举例。

![数组-数组地址](https://archive.static.spiritling.net/images/02_Array-ArrayAddress.png)

在上面的图中，计算机给数组 a[10] ，分配了一块连续内存空间 1100 ~ 1139 ，其中，内存块的首地址为 base_address_code = 1000。计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址：

```
a[i]_address_code = base_address_code + i * data_type_size
```

其中 data_type_size 表示数组中每个元素的大小。比如：在我们所举的例子中，数组中存储的 int 类型数据，所以 data_type_size 就为 4 个字节。

回到上面的问题，为什么不从 1 开始呢？

```
a[k]_address = base_address + (k-1)*type_size
```

可以通过上面代码看出，如果从 1 开始，每次访问随机数组元素都多了一次减法运算，对于 CPU 来说，就是多了一次减法指令。

数组作为非常基础的数据结构，通过下标随机访问数组元素又是其非常基础的编程操作，效率的优化就要尽可能做到极致。所以为了减少一次减法操作，数组选择了从 0 开始编号，而不是从 1 开始。

不过我认为，从 0 开始，应该是一个历史问题。当初 C 语言设计者用 0 开始计数数组下标，后续高级语言都效仿了 C 语言设计。

## 插入和删除

前面已经说过了，因为数组的连续存储性导致的“随机访问”有利有弊。所以间接导致数组的插入和删除比较低效。

### 插入操作

假设数组长度为 n ，现在，如果我们需要将一个数据插入到数组中的第 k 个位置。为了把第 k 个位置腾出来，让新的数据放入进去，需要将第 k ~ n 这部分的数据元素都顺序地往后挪一挪。

已经学过了算法的复杂度分析，可以试着使用它来进行分析。

如果在数据的开头插入数据元素，那所有的数据元素都需要以此往后移动一位，所以最坏时间复杂度是 O(n)；如果在数组的末尾插入元素，那就不需要移动任何一位，这时的时间复杂度为 O(1)。因为在每个位置插入元素的概率一样，所以平均时间复杂度为 (1+2+...+n)/n = O(n)。

如果数组中的数据是有序的，我们在某个位置插入一个新的元素时，就必须按照刚才的方法搬移 k 之后的数据。但是，如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数据插入到第 k 个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置。

### 删除操作

跟插入操作类似，如果需要删除第 k 个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。

和插入类似，如果删除开头的数据，则最坏情况时间复杂度为 O(n)；如果删除数组末尾的数据，则最好情况时间复杂度为 O(1)；平均情况时间复杂度也为 O(n)。

实际上，在某些场景下，我们并不一定非得追求数组中数据的连续性。如果我们将多次删除操作集中在一起进行时，删除的效率远远比每次删除操作都执行要提高很多。

数组 a[10]中存储了 8 个元素：a，b，c，d，e，f，g，h。现在，我们要依次删除 a，b，c 三个元素。

为了避免 d，e，f，g，h 这几个数据会被搬移三次，我们可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。

如果你了解 JVM，你会发现，这不就是 JVM 标记清除垃圾回收算法的核心思想吗？没错，数据结构和算法的魅力就在于此，**很多时候我们并不是要去死记硬背某个数据结构或者算法，而是要学习它背后的思想和处理技巧，这些东西才是最有价值的**。如果你细心留意，不管是在软件开发还是架构设计中，总能找到某些算法和数据结构的影子。

## 数组的访问越界问题

前面讲了数组的几个基本操作后，现在来讲讲数组的访问越界问题。

```c
int main(int argc, char* argv[]){
    int i = 0;
    int arr[3] = {0};
    for(; i<=3; i++){
        arr[i] = 0;
        printf("hello world\n");
    }
    return 0;
}
```

运行这段代码，并不是你所想的打印三行 “hello word”，而是会无限打印“hello word”，这是因为什么呢？

因为，数组大小为 3，a[0]，a[1]，a[2]，而我们的代码因为书写错误，导致 for 循环的结束条件错写为了 i<=3 而非 i<3，所以当 i=3 时，数组 a[3]访问越界。

在 C 语言中，只要不是访问受限的内存，所有的内存空间都是可以自由访问的。根据我们前面讲的数组寻址公式，a[3]也会被定位到某块不属于数组的内存地址上，而这个地址正好是存储变量 i 的内存地址，那么 a[3]=0 就相当于 i=0，所以就会导致代码无限循环。

数组越界在 C 语言中是一种未决行为，并没有规定数组访问越界时编译器应该如何处理。因为，访问数组的本质就是访问一段连续内存，只要数组通过偏移计算得到的内存地址是可用的，那么程序就可能不会报任何错误。

正常情况下，一般都会出现莫名其妙的逻辑错误，就像我们刚刚举的那个例子，debug 的难度非常的大。而且，很多计算机病毒也正是利用到了代码中的数组越界可以访问非法地址的漏洞，来攻击系统，所以写代码的时候一定要警惕数组越界。

但并非所有的语言都像 C 一样，把数组越界检查的工作丢给程序员来做，像 Java 本身就会做越界检查，比如下面这几行 Java 代码，就会抛出 `java.lang.ArrayIndexOutOfBoundsException`。

```java
int[] a = new int[3];
a[3] = 10;
```

## 容器是否可以替代数据？

针对数组类型，很多语言都提供了容器类，比如 C# 中的 List。

使用 c# 举例，List 最大的优势就是**可以将数组的许多操作的细节封装起来**。比如上面的插入和删除操作。另外，它还**支持动态扩容**。

数组本身在定义的时候需要预先指定大小，因为需要分配连续的内存空间。如果我们申请了大小为 10 的数组，当第 11 个数据需要存储到数组中时，我们就需要重新分配一块更大的空间，将原来的数据复制过去，然后再将新的数据插入。

如果使用 List，我们就完全不需要关心底层的扩容逻辑，List 已经帮我们实现好了。每次存储空间不够的时候，它都会将空间自动扩容为 1.5 倍大小。

不过，这里需要注意一点，因为扩容操作涉及内存申请和数据搬移，是比较耗时的。所以，如果事先能确定需要存储的数据大小，最好在创建 List 的时候事先指定数据大小。

对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选。
